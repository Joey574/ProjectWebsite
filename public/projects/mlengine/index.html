<!-- /projects/mlengine -->

<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>MLEngine</title>
    
    <link rel="stylesheet" href="/static/css/style.css">
    <link rel="stylesheet" href="/static/css/mermaid.css">

    <script src="https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js"></script>
    <script>
        mermaid.initialize({ startOnLoad: true, theme: "dark" });
    </script>
</head>
<body>
     <header>
        <h1><a href="/projects">Projects</a></h1>
        <nav>
            <a href="/">Home</a>
        </nav>
    </header>

    <main>
        <h2>MLEngine</h2>
        <p>
            MLEngine is a C++ command line tool for linux aimed to allow easy iteration on different neural network designs
        </p>

        <h3>Description</h3>
        <p>
            Written from scratch in C++, MLEngine is a Machine Learning framework that allows a user to implement all sorts of machine 
            learning concepts, currently does not support GPUs but bound to change one day. Highly optimized and customizable, a user 
            can define what dataset to train on, the name of the model, model dimensions, activations, weight initilization, loss, scoring, 
            and various other options that are used during training.
            <br><br>

            Much of the mathematical code has been lifted from a previous project of mine, specifically, the core is very similair to the 
            SingleBlockNeuralNetwork version, though many orginizational changes have been made. That proejct was much more focused on just 
            getting the math right, it allowed me to form an understanding of how neural networks worked but was by no means easy to use. 
            This project aims to change that, primarily by making it a command line tool and allowing easy iterations of different neural 
            network designs.  
        </p>

        <h3>How it Works</h3>
        <p>
            MLEngine uses a general top down framework to allow vast customizability and modification while maintaining performance through 
            use of templates, the following chart depicts the top down approach and the ownership / level different structs exist on.
        </p>
        <div class="mermaid">
        flowchart TD
            state["State"]
            nn["NeuralNetwork"]
            layer["Layer"]
            dataload["DataLoader"]
            actv["Activation"]
            lossmetric["LossMetric"]
            optimizer["Optimizer"]
            mathutils["MathUtils"]

            state --> nn
            state --> dataload

            nn --> layer
            nn --> dataload

            layer --> actv
            layer --> lossmetric
            layer --> optimizer
        </div>

        <ul>
            <li><strong>State</strong>: Responsible for all high-level actions such as saving and loading configs from disk.</li>
            <li><strong>MathUtils</strong>: Stands alone but is used by many of the structs for highly optimized math utilities.</li>
            <li><strong>NeuralNetwork</strong>: Manages the memory allocation of the network and training state.</li>
            <li><strong>Layer</strong>: The workhorse, implementing key machine learning algorithms.</li>
            <li><strong>DataLoader</strong>: Handles dataset loading from disk and performs augmentations if needed.</li>
            <li><strong>Activation</strong>: Implements activation functions and their derivatives.</li>
            <li><strong>LossMetric</strong>: Responsible for scoring and loss functions.</li>
            <li><strong>Optimizer</strong>: Manages parameter updates and implements various optimization algorithms.</li>
        </ul>

    </main>

    <footer>
        <p>&copy; 2025 Joseph Soroka. All rights reserved.</p>
    </footer>
</body>
</html>
